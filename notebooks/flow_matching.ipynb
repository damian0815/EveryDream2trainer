{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "id": "574fdbf0e8376686",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from diffusers.training_utils import compute_loss_weighting_for_sd3\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for schema in [#'sigma_sqrt',\n",
    "     'cosmap']:\n",
    "    print(schema)\n",
    "    print(compute_loss_weighting_for_sd3(weighting_scheme=schema, sigmas=torch.linspace(0.0001, 1, 20)))\n",
    "    _ = plt.plot(compute_loss_weighting_for_sd3(weighting_scheme=schema, sigmas=torch.linspace(0.0001, 1, 1000)))\n",
    "\n"
   ],
   "id": "9ba07b230f09aa62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_flow_matching_min_snr_weights(t, min_snr_gamma):\n",
    "        \"\"\"\n",
    "        Compute min-SNR(gamma) weighting from timesteps.\n",
    "\n",
    "        For flow-matching, SNR(t) ≈ t²/(1-t)² based on the interpolation schedule.\n",
    "        We clip this to prevent extreme weights at t→0 or t→1.\n",
    "\n",
    "        Args:\n",
    "            t: Timesteps [B]\n",
    "\n",
    "        Returns:\n",
    "            Weights [B]\n",
    "        \"\"\"\n",
    "        # Avoid division by zero at boundaries\n",
    "        t_clamped = torch.clamp(t, min=1e-5, max=1 - 1e-5)\n",
    "\n",
    "        # Compute SNR for flow-matching interpolation\n",
    "        # SNR(t) = signal²/noise² = t²/(1-t)²\n",
    "        snr = (t_clamped ** 2) / ((1 - t_clamped) ** 2)\n",
    "\n",
    "        # Apply min-SNR clipping\n",
    "        snr_capped = torch.minimum(snr, torch.tensor(min_snr_gamma))\n",
    "\n",
    "        # Weight is inverse of capped SNR (higher weight for harder timesteps)\n",
    "        # Add 1 to prevent division issues when snr=0\n",
    "        weights = 1.0 / (snr_capped + 1.0)\n",
    "\n",
    "        return weights\n",
    "\n",
    "_ = plt.plot(compute_flow_matching_min_snr_weights(t=torch.linspace(0.01, 1, 1000), min_snr_gamma=5))\n"
   ],
   "id": "704aa155ba055c15",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained('/workspace/models/sdsf-97k-1e5qrt-12k-4e6sqrt-11k-h')\n",
    "pipe.to('cuda')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from diffusers import UNet2DConditionModel\n",
    "import torch\n",
    "encoder_hidden_states = torch.randn((1, 77, 1024), device=pipe.device)\n",
    "sample = torch.randn((1, 4, 64, 64), device=pipe.device)\n",
    "t = 1\n",
    "torch.set_grad_enabled(False)\n",
    "unet: UNet2DConditionModel = pipe.unet\n",
    "unet.forward(sample, t, encoder_hidden_states)"
   ],
   "id": "e12f73487df4ef23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from diffusers import FlowMatchEulerDiscreteScheduler, DDPMScheduler\n",
    "\n",
    "ddpm_scheduler = DDPMScheduler()\n",
    "ddpm_scheduler.alphas_cumprod\n"
   ],
   "id": "716efddde1cd493e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flow_match_scheduler = FlowMatchEulerDiscreteScheduler()\n",
    "flow_match_scheduler.sigmas\n"
   ],
   "id": "884ea09a12e425cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "flow_match_scheduler.set_timesteps(num_inference_steps=999)",
   "id": "82ccc27979e491c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "flow_match_scheduler.sigmas",
   "id": "901bb7fd02e05cbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "flow_match_scheduler.config.num_train_timesteps",
   "id": "e69bc4c39b729608",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from flow_match_model import TrainFlowMatchScheduler\n",
    "\n",
    "fm_test = TrainFlowMatchScheduler()\n",
    "latents = torch.zeros((2, 2, 4, 4))\n",
    "noise = torch.randn((2, 2, 4, 4))\n",
    "timesteps = torch.tensor([25, 800]).float()\n",
    "fm_test.add_noise(latents, noise=noise, timesteps=timesteps)"
   ],
   "id": "9a66f1ead95fc32d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from diffusers import FlowMatchEulerDiscreteScheduler\n",
    "\n",
    "scheduler = FlowMatchEulerDiscreteScheduler.from_config(pipe.scheduler.config)"
   ],
   "id": "4d1e36227b3c3c73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pipe.scheduler = scheduler\n",
    "\n",
    "pipe.to('cuda')"
   ],
   "id": "9b0b7073b7f3847d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompt = \"A cat in a forest\"\n",
    "pipe: StableDiffusionPipeline\n",
    "pipe.scheduler.init_noise_sigma = 1\n",
    "pipe.scheduler.scale_model_input = lambda x, t: x\n",
    "images = pipe(prompt=prompt, negative_prompt=\"ugly, pointillism\", height=768, width=768, num_inference_steps=30)    \n"
   ],
   "id": "5e9f49bbb3832aa8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "images.images[0]",
   "id": "7ab35cf513909f5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "def _get_polynomial_decay_schedule_with_warmup_adj(\n",
    "    lr_init: float,\n",
    "    num_warmup_steps: int,\n",
    "    num_training_steps: int,\n",
    "    num_cycles: int = 1,\n",
    "    lr_end: float = 1e-7,\n",
    "    power: float = 1.0,\n",
    "    last_epoch: int = -1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Adapted from diffusers get_polynomial_decay_schedule_with_warmup to remove the restrictive check on strictly decreasing LR\n",
    "\n",
    "    Create a schedule with a learning rate that decreases as a polynomial decay from the initial lr set in the\n",
    "    optimizer to end lr defined by *lr_end*, after a warmup period during which it increases linearly from 0 to the\n",
    "    initial lr set in the optimizer.\n",
    "\n",
    "    Args:\n",
    "        optimizer ([`~torch.optim.Optimizer`]):\n",
    "            The optimizer for which to schedule the learning rate.\n",
    "        num_warmup_steps (`int`):\n",
    "            The number of steps for the warmup phase.\n",
    "        num_training_steps (`int`):\n",
    "            The total number of training steps.\n",
    "        lr_end (`float`, *optional*, defaults to 1e-7):\n",
    "            The end LR.\n",
    "        power (`float`, *optional*, defaults to 1.0):\n",
    "            Power factor.\n",
    "        last_epoch (`int`, *optional*, defaults to -1):\n",
    "            The index of the last epoch when resuming training.\n",
    "        num_cycles (`int`, *optional*, defaults to 1):\n",
    "            How many times to repeat the cycle of warmup/cooldown during training.\n",
    "\n",
    "    Note: *power* defaults to 1.0 as in the fairseq implementation, which in turn is based on the original BERT\n",
    "    implementation at\n",
    "    https://github.com/google-research/bert/blob/f39e881b169b9d53bea03d2d341b31707a6c052b/optimization.py#L37\n",
    "\n",
    "    Return:\n",
    "        `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    num_warmup_steps_cycle = math.ceil(num_warmup_steps / num_cycles)\n",
    "    num_training_steps_cycle = math.ceil(num_training_steps / num_cycles)\n",
    "\n",
    "    def lr_lambda_cycleinternal(current_cycle_step: int):\n",
    "        if current_cycle_step < num_warmup_steps_cycle:\n",
    "            return float(current_cycle_step) / float(max(1, num_warmup_steps_cycle))\n",
    "        elif current_cycle_step > num_training_steps_cycle:\n",
    "            return lr_end / lr_init  # as LambdaLR multiplies by lr_init\n",
    "        else:\n",
    "            lr_range = lr_init - lr_end\n",
    "            decay_steps = num_training_steps_cycle - num_warmup_steps_cycle\n",
    "            pct_remaining = 1 - (current_cycle_step - num_warmup_steps_cycle) / decay_steps\n",
    "            print('pct_remaining', pct_remaining)\n",
    "            decay = lr_range * pct_remaining**power + lr_end\n",
    "            print('lr_range', lr_range, 'power', power, 'decay', decay)\n",
    "            return decay / lr_init  # as LambdaLR multiplies by lr_init\n",
    "\n",
    "    def lr_lambda(current_step: int):\n",
    "        current_cycle_step = current_step % int(num_warmup_steps_cycle + num_training_steps_cycle)\n",
    "        return lr_lambda_cycleinternal(current_cycle_step)\n",
    "\n",
    "    return lr_lambda\n",
    "\n",
    "ll = _get_polynomial_decay_schedule_with_warmup_adj(1e-3, lr_end=1e-1, num_warmup_steps=0, num_training_steps=200, power=2)"
   ],
   "id": "d15dec260a0a1ecb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_warmup_steps = 1000\n",
    "max_lr = 1e-4\n",
    "min_lr = 1e-8\n",
    "\n",
    "def findlr_lambda(current_step: int):\n",
    "    if current_step >= num_warmup_steps:\n",
    "        return max_lr\n",
    "\n",
    "    t = current_step / num_warmup_steps\n",
    "    return min_lr * (max_lr / min_lr) ** t\n",
    "\n",
    "def findlr_lambda_(current_step: int):\n",
    "    if current_step < num_warmup_steps:\n",
    "        pos = current_step / num_warmup_steps\n",
    "        return min_lr + (pos ** power) * (max_lr - min_lr)\n",
    "    else:\n",
    "        return max_lr\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "_ = plt.plot([findlr_lambda(x) for x in range(2000)])"
   ],
   "id": "c0e68da20b0136bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2b69398de8436aa5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ll(0)",
   "id": "3a9ce18d349dc484",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ll(199)",
   "id": "48e8c79127c646f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7c02f38b766e5b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /workspace/EveryDream2trainer-remote"
   ],
   "id": "31a48c4339eb814d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from flow_match_model import TrainFlowMatchScheduler\n",
    "s = TrainFlowMatchScheduler()\n"
   ],
   "id": "2561000d62d90186",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from model.training_model import get_training_noise_scheduler\n",
    "\n",
    "flow_match_shift = 3\n",
    "noise_scheduler = get_training_noise_scheduler(s, \"flow-matching\",\n",
    "                                                       trained_betas=[],\n",
    "                                                       rescale_betas_zero_snr=False,\n",
    "                                                       flow_match_shift=flow_match_shift\n",
    "                                               )\n"
   ],
   "id": "4bec307c5762be9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from model.training_model import TrainFlowMatchScheduler\n",
    "noise_scheduler = TrainFlowMatchScheduler(shift=3)\n",
    "noise_scheduler.sigmas * 1000 - noise_scheduler.timesteps\n"
   ],
   "id": "c4194da84c463058",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "ex = noise_scheduler.get_exact_timesteps(torch.tensor([0, 1, 998, 999]))\n",
    "ex"
   ],
   "id": "b6495c94452772dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f96eb92d50fd90f6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
