{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-21T10:58:54.375422Z",
     "start_time": "2025-08-21T10:58:50.211239Z"
    }
   },
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained('stabilityai/stable-diffusion-xl-base-1.0')\n",
    "#pipe = StableDiffusionXLPipeline.from_pretrained('/workspace/models/Juggernaut-XL-v9')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damian/2.current/EveryDream2trainer/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/damian/2.current/EveryDream2trainer/.venv/lib/python3.12/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 12.81it/s]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:00:51.407138Z",
     "start_time": "2025-08-21T11:55:20.872690Z"
    }
   },
   "cell_type": "code",
   "source": "pipe(\"a cat\", width=576, height=448)",
   "id": "c7903ceb63a0dea3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damian/2.current/EveryDream2trainer/.venv/lib/python3.12/site-packages/diffusers/configuration_utils.py:141: FutureWarning: Accessing config attribute `__len__` directly via 'StableDiffusionXLPipeline' object attribute is deprecated. Please access '__len__' over 'StableDiffusionXLPipeline's config object instead, e.g. 'scheduler.config.__len__'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mpipe\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43ma cat\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwidth\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m576\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheight\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m448\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/2.current/EveryDream2trainer/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/2.current/EveryDream2trainer/.venv/lib/python3.12/site-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py:1095\u001B[39m, in \u001B[36mStableDiffusionXLPipeline.__call__\u001B[39m\u001B[34m(self, prompt, prompt_2, height, width, num_inference_steps, timesteps, sigmas, denoising_end, guidance_scale, negative_prompt, negative_prompt_2, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, original_size, crops_coords_top_left, target_size, negative_original_size, negative_crops_coords_top_left, negative_target_size, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001B[39m\n\u001B[32m   1085\u001B[39m \u001B[38;5;66;03m# 3. Encode input prompt\u001B[39;00m\n\u001B[32m   1086\u001B[39m lora_scale = (\n\u001B[32m   1087\u001B[39m     \u001B[38;5;28mself\u001B[39m.cross_attention_kwargs.get(\u001B[33m\"\u001B[39m\u001B[33mscale\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.cross_attention_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1088\u001B[39m )\n\u001B[32m   1090\u001B[39m (\n\u001B[32m   1091\u001B[39m     prompt_embeds,\n\u001B[32m   1092\u001B[39m     negative_prompt_embeds,\n\u001B[32m   1093\u001B[39m     pooled_prompt_embeds,\n\u001B[32m   1094\u001B[39m     negative_pooled_prompt_embeds,\n\u001B[32m-> \u001B[39m\u001B[32m1095\u001B[39m ) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencode_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1096\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1097\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprompt_2\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprompt_2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1098\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1099\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_images_per_prompt\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_images_per_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1100\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdo_classifier_free_guidance\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdo_classifier_free_guidance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1101\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnegative_prompt\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnegative_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1102\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnegative_prompt_2\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnegative_prompt_2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1103\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprompt_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprompt_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1104\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnegative_prompt_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnegative_prompt_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1105\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpooled_prompt_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpooled_prompt_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1106\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnegative_pooled_prompt_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnegative_pooled_prompt_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1107\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlora_scale\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlora_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1108\u001B[39m \u001B[43m    \u001B[49m\u001B[43mclip_skip\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclip_skip\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1109\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1111\u001B[39m \u001B[38;5;66;03m# 4. Prepare timesteps\u001B[39;00m\n\u001B[32m   1112\u001B[39m timesteps, num_inference_steps = retrieve_timesteps(\n\u001B[32m   1113\u001B[39m     \u001B[38;5;28mself\u001B[39m.scheduler, num_inference_steps, device, timesteps, sigmas\n\u001B[32m   1114\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/2.current/EveryDream2trainer/.venv/lib/python3.12/site-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py:428\u001B[39m, in \u001B[36mStableDiffusionXLPipeline.encode_prompt\u001B[39m\u001B[34m(self, prompt, prompt_2, device, num_images_per_prompt, do_classifier_free_guidance, negative_prompt, negative_prompt_2, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, lora_scale, clip_skip)\u001B[39m\n\u001B[32m    426\u001B[39m \u001B[38;5;66;03m# get unconditional embeddings for classifier free guidance\u001B[39;00m\n\u001B[32m    427\u001B[39m zero_out_negative_prompt = negative_prompt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.force_zeros_for_empty_prompt\n\u001B[32m--> \u001B[39m\u001B[32m428\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mdo_classifier_free_guidance\u001B[49m \u001B[38;5;129;01mand\u001B[39;00m negative_prompt_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m zero_out_negative_prompt:\n\u001B[32m    429\u001B[39m     negative_prompt_embeds = torch.zeros_like(prompt_embeds)\n\u001B[32m    430\u001B[39m     negative_pooled_prompt_embeds = torch.zeros_like(pooled_prompt_embeds)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:892\u001B[39m, in \u001B[36mPyDBFrame.trace_dispatch\u001B[39m\u001B[34m(self, frame, event, arg)\u001B[39m\n\u001B[32m    890\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_line:\n\u001B[32m    891\u001B[39m     \u001B[38;5;28mself\u001B[39m.set_suspend(thread, step_cmd)\n\u001B[32m--> \u001B[39m\u001B[32m892\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    893\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# return event\u001B[39;00m\n\u001B[32m    894\u001B[39m     back = frame.f_back\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:412\u001B[39m, in \u001B[36mPyDBFrame.do_wait_suspend\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    411\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m412\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[39m, in \u001B[36mPyDB.do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[39m\n\u001B[32m   1217\u001B[39m         from_this_thread.append(frame_id)\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, stop_reason):\n\u001B[32m-> \u001B[39m\u001B[32m1220\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1235\u001B[39m, in \u001B[36mPyDB._do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[39m\n\u001B[32m   1232\u001B[39m             \u001B[38;5;28mself\u001B[39m._call_mpl_hook()\n\u001B[32m   1234\u001B[39m         \u001B[38;5;28mself\u001B[39m.process_internal_commands()\n\u001B[32m-> \u001B[39m\u001B[32m1235\u001B[39m         \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1237\u001B[39m \u001B[38;5;28mself\u001B[39m.cancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[32m   1239\u001B[39m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T11:00:31.905637Z",
     "start_time": "2025-08-21T11:00:31.899581Z"
    }
   },
   "cell_type": "code",
   "source": "pipe.text_encoder_2.config",
   "id": "840100f707c6e78c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPTextConfig {\n",
       "  \"architectures\": [\n",
       "    \"CLIPTextModelWithProjection\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"dropout\": 0.0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_size\": 1280,\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 5120,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 77,\n",
       "  \"model_type\": \"clip_text_model\",\n",
       "  \"num_attention_heads\": 20,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"projection_dim\": 1280,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.55.2\",\n",
       "  \"vocab_size\": 49408\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf758242de761fd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T18:43:43.953708Z",
     "start_time": "2025-08-30T18:43:42.849006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained('RunDiffusion/Juggernaut-XI-v11')"
   ],
   "id": "2914c10713e34cae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd334b521d4040549447a3eb5d3b7d28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch /root/.cache/huggingface/hub/models--RunDiffusion--Juggernaut-XI-v11/snapshots/17a87abb089586ab38591a2309da18e44e2c8917/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--RunDiffusion--Juggernaut-XI-v11/snapshots/17a87abb089586ab38591a2309da18e44e2c8917/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "/workspace/venv/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "An error occurred while trying to fetch /root/.cache/huggingface/hub/models--RunDiffusion--Juggernaut-XI-v11/snapshots/17a87abb089586ab38591a2309da18e44e2c8917/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--RunDiffusion--Juggernaut-XI-v11/snapshots/17a87abb089586ab38591a2309da18e44e2c8917/unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T18:44:56.017148Z",
     "start_time": "2025-08-30T18:44:56.011484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from diffusers import DPMSolverMultistepScheduler\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config, algorithm_type=\"dpmsolver++\", use_karras_sigmas=True)"
   ],
   "id": "5cfafe45581d2bcb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T12:52:48.255008Z",
     "start_time": "2025-09-02T12:52:48.124630Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "47d7b103fd82aef7",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      2\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_records([{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpath\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/a/b\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1\u001B[39m}, \n\u001B[1;32m      3\u001B[0m                                 {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpath\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/a/c\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m2\u001B[39m},\n\u001B[1;32m      4\u001B[0m                                 {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpath\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/a/d\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m},\n\u001B[1;32m      5\u001B[0m                                 {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpath\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/a/b\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m2\u001B[39m}])\u001B[38;5;241m.\u001B[39mset_index(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpath\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      7\u001B[0m df\u001B[38;5;241m.\u001B[39mdropna(subset\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/a/b\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pandas'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fde80d7aa0ead275"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
